"""
Cliente para comunicaci√≥n con LM Studio API.
"""

import json
import logging
import requests
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)


class LMStudioClient:
    """Cliente para interactuar con LM Studio API."""
    
    def __init__(self, base_url: str = "http://127.0.0.1:1234", model_name: str = "openai/gpt-oss-20b"):
        """
        Inicializa cliente LM Studio.
        
        Args:
            base_url: URL base del servidor LM Studio
            model_name: Nombre del modelo a usar
        """
        self.base_url = base_url.rstrip('/')
        self.model_name = model_name
        self.is_connected = False
        self.available_models = []
        
    def connect(self) -> bool:
        """
        Conecta con LM Studio y verifica disponibilidad del modelo.
        
        Returns:
            bool: True si conexi√≥n exitosa, False en caso contrario
        """
        try:
            logger.info("Intentando conectar con LM Studio...")
            
            response = requests.get(f"{self.base_url}/v1/models", timeout=5)
            if response.status_code == 200:
                models_data = response.json()
                self.available_models = [m.get('id', '') for m in models_data.get('data', [])]
                logger.info(f"‚úÖ LM Studio conectado. Modelos: {self.available_models}")
                
                # Verificar que nuestro modelo est√° disponible
                if any(self.model_name in model for model in self.available_models):
                    self.is_connected = True
                    logger.info(f"üéØ Modelo {self.model_name} disponible")
                    return True
                else:
                    logger.warning(f"‚ö†Ô∏è Modelo {self.model_name} no encontrado")
                    return False
            else:
                raise Exception(f"Error de conexi√≥n: {response.status_code}")
                
        except requests.exceptions.ConnectionError:
            logger.warning("‚ö†Ô∏è LM Studio no est√° corriendo")
            return False
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error conectando con LM Studio: {str(e)}")
            return False
    
    def generate_text(self, prompt: str, max_tokens: int = 1000, temperature: float = 0.7) -> Optional[str]:
        """
        Genera texto usando LM Studio API.
        
        Args:
            prompt: Texto de entrada
            max_tokens: M√°ximo n√∫mero de tokens
            temperature: Temperatura para generaci√≥n
            
        Returns:
            str: Texto generado o None si error
        """
        if not self.is_connected:
            logger.error("Cliente no conectado a LM Studio")
            return None
            
        try:
            logger.info("üöÄ Evaluando con LM Studio...")
            
            payload = {
                "model": self.model_name,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": max_tokens,
                "temperature": temperature,
                "stream": False
            }
            
            response = requests.post(
                f"{self.base_url}/v1/chat/completions",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                content = data['choices'][0]['message']['content']
                logger.info("üìù Respuesta recibida de LM Studio")
                return content
            else:
                logger.error(f"Error en respuesta LM Studio: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"Error generando texto: {str(e)}")
            return None
    
    def evaluate_invest_story(self, historia: str) -> Optional[Dict]:
        """
        Eval√∫a historia usando LM Studio con prompt espec√≠fico para INVEST.
        
        Args:
            historia: Historia de usuario a evaluar
            
        Returns:
            dict: Resultado de evaluaci√≥n o None si error
        """
        prompt = f"""Eres un Product Owner pragm√°tico evaluando esta historia de usuario. Usa criterios INVEST pero con mentalidad pr√°ctica de equipo √°gil:

                    Historia: "{historia}"

                    **Eval√∫a con criterio pr√°ctico:**

                    **Independiente**: ¬øSe puede trabajar sin depender cr√≠ticamente de otras historias espec√≠ficas?
                    (Acepta dependencias de infraestructura com√∫n como autenticaci√≥n, base de datos, etc.)

                    **Negociable**: ¬øEl equipo puede conversar sobre el alcance durante el desarrollo?
                    (Si tiene formato "Como X quiero Y para Z", generalmente es negociable)

                    **Valiosa**: ¬øResuelve un problema real del usuario o aporta valor al negocio?
                    (Si es funcionalidad que usuarios realmente usar√≠an)

                    **Estimable**: ¬øEl equipo de desarrollo puede entender qu√© construir y estimar esfuerzo?
                    (No necesita ser perfecta, solo suficiente claridad para developers)

                    **Small**: ¬øSe puede completar en 1-2 semanas por el equipo?
                    (Si no es una √©pica gigante con m√∫ltiples flujos complejos)

                    **Testeable**: ¬øSe puede verificar que funciona correctamente?
                    (Si puedes definir criterios b√°sicos de "terminado")

                    **Gu√≠as pr√°cticas:**
                    - Historias con formato correcto "Como X quiero Y para Z" ya cumplen varios criterios
                    - Solo marca FALSE si hay problemas evidentes que bloquear√≠an el desarrollo
                    - Prioriza valor funcional sobre perfecci√≥n acad√©mica
                    - Equipos √°giles pueden refinar historias durante el sprint

                    Responde SOLO con JSON v√°lido:
                    {{
                    "Independiente": true/false,
                    "Negociable": true/false,
                    "Valiosa": true/false,
                    "Estimable": true/false,
                    "Small": true/false,
                    "Testeable": true/false,
                    "sugerencias": ["sugerencia pr√°ctica 1", "sugerencia pr√°ctica 2"]
                    }}

                    Sugerencias solo para criterios FALSE, y deben ser espec√≠ficas y ejecutables."""

        response_text = self.generate_text(prompt, max_tokens=500, temperature=0.3)
        
        if response_text:
            try:
                # Limpiar respuesta y extraer JSON
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                
                if json_start >= 0 and json_end > json_start:
                    json_str = response_text[json_start:json_end]
                    return json.loads(json_str)
                else:
                    logger.error("No se encontr√≥ JSON v√°lido en la respuesta")
                    return None
                    
            except json.JSONDecodeError as e:
                logger.error(f"Error parseando JSON de LM Studio: {str(e)}")
                return None
        
        return None
    
    def estimate_development_time(self, historia: str, invest_scores: Dict = None) -> Optional[float]:
        """
        Estima tiempo de desarrollo usando LM Studio con prompt espec√≠fico para estimaci√≥n.
        
        Args:
            historia: Historia de usuario a evaluar
            invest_scores: Scores INVEST opcionales para contexto adicional
            
        Returns:
            float: Tiempo estimado en horas o None si error
        """
        # Construir contexto adicional si hay scores INVEST
        contexto_invest = ""
        if invest_scores:
            criterios_cumplidos = sum(1 for v in invest_scores.values() if v)
            contexto_invest = f"""
            Contexto INVEST (criterios cumplidos: {criterios_cumplidos}/6):
            - Independiente: {'‚úì' if invest_scores.get('Independiente', False) else '‚úó'}
            - Negociable: {'‚úì' if invest_scores.get('Negociable', False) else '‚úó'}
            - Valiosa: {'‚úì' if invest_scores.get('Valiosa', False) else '‚úó'}
            - Estimable: {'‚úì' if invest_scores.get('Estimable', False) else '‚úó'}
            - Small: {'‚úì' if invest_scores.get('Small', False) else '‚úó'}
            - Testeable: {'‚úì' if invest_scores.get('Testeable', False) else '‚úó'}
            """

        prompt = f"""Como un experto en estimaci√≥n de desarrollo de software con m√°s de 10 a√±os de experiencia, necesitas estimar el tiempo de desarrollo para esta historia de usuario.

                Historia de usuario: "{historia}"
                {contexto_invest}

                Considera los siguientes factores para tu estimaci√≥n:
                1. Complejidad t√©cnica de la implementaci√≥n
                2. Cantidad de componentes involucrados (frontend, backend, base de datos)
                3. Necesidad de investigaci√≥n o aprendizaje
                4. Testing y validaci√≥n requeridos
                5. Integraci√≥n con sistemas existentes
                6. Calidad de los criterios INVEST (historias mejor definidas = estimaci√≥n m√°s precisa)

                Factores de tiempo t√≠picos:
                - Historia simple (formulario b√°sico, CRUD simple): 4-8 horas
                - Historia media (l√≥gica de negocio, validaciones, integraciones simples): 8-16 horas
                - Historia compleja (algoritmos complejos, m√∫ltiples integraciones, UI avanzada): 16-32 horas
                - Historia muy compleja (nueva arquitectura, investigaci√≥n, m√∫ltiples sistemas): 32+ horas

                IMPORTANTE: Responde SOLO con un n√∫mero decimal que represente las horas estimadas. 
                No incluyas texto adicional, explicaciones o rangos. Solo el n√∫mero.

                Ejemplo de respuesta correcta: 12.5
                Ejemplo de respuesta incorrecta: "Entre 10 y 15 horas" o "12.5 horas"

                Tiempo estimado en horas:"""

        response_text = self.generate_text(prompt, max_tokens=50, temperature=0.3)
        
        if response_text:
            try:
                # Extraer n√∫mero de la respuesta
                import re
                # Buscar n√∫mero decimal en la respuesta
                match = re.search(r'\d+\.?\d*', response_text.strip())
                if match:
                    tiempo_estimado = float(match.group())
                    # Validar rango razonable (1-100 horas)
                    if 1.0 <= tiempo_estimado <= 100.0:
                        logger.info(f"‚è±Ô∏è Tiempo estimado por LLM: {tiempo_estimado} horas")
                        return tiempo_estimado
                    else:
                        logger.warning(f"Tiempo estimado fuera de rango: {tiempo_estimado}")
                        return None
                else:
                    logger.error("No se encontr√≥ n√∫mero v√°lido en la respuesta del LLM")
                    return None
                    
            except (ValueError, TypeError) as e:
                logger.error(f"Error parseando tiempo estimado: {str(e)}")
                return None
        
        return None
    
    def is_available(self) -> bool:
        """Verifica si el cliente est√° conectado y disponible."""
        return self.is_connected
    
    def get_available_models(self) -> List[str]:
        """Retorna lista de modelos disponibles."""
        return self.available_models.copy()
